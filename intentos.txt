# for key, value in ntas.items():
#     poly=Polygon(value)
#     print (poly)
#     break

# print()
# print(poly.contains(Point(green.dataFrame['pickup_longitude'][0],green.dataFrame['pickup_latitude'][0])))
#green.dataFrame["nta"]= green.dataFrame.apply(lambda row: settingNta(row['pickup_latitude'],row['pickup_longitude']),axis=1)

# import tqdm                               
# import numpy as np
# import pandas as pd
# from concurrent.futures import ProcessPoolExecutor, as_completed
# from multiprocessing import freeze_support, cpu_count
# num_processes = cpu_count()

# from DS4A.worker import func

# if __name__ == '__main__':
   
#     df = pd.DataFrame({i: np.random.randint(1,10,size=100) for i in ['a', 'b', 'c']})
#     # Process the rows in chunks in parallel
#     print("Starting ...")
#     with ProcessPoolExecutor(1) as pool:
#         #df['result'] = list(pool.map(func, df['a'], df['b'], chunksize=10)) # Without a progressbar
#         df['result'] = list(tqdm.tqdm(pool.map(func, df['a'], df['b'], chunksize=10), total=df.shape[0])) # With a progressbar

#     print(df)


# with concurrent.futures.ProcessPoolExecutor(max_workers=3) as pool:
#     green.dataFrame["nta"]= list(tqdm(pool.map(settingNta, green.dataFrame["pickup_latitude"], green.dataFrame["pickup_longitude"], chunksize=10),green.dataFrame.shape[0]))
#     green.dataFrame.to_csv('myFile.csv',encoding='utf-8',index=False)
#     green.dataFrame.head()    



'''
with ThreadPoolExecutor(max_workers=2) as executor:
    futures=[]
    for file in listOfFiles:
        future = executor.submit(pd.read_csv,file,low_memory=False)
        futures.append(future)
        listOfDataFrames[Path(file).stem]= [file, future.result()]

    for _ in tqdm(as_completed(futures), **tqdmargs):
        pass
'''


#experiment on how to update dataframes with nta column
#green=listOfDataSets['green_trips']

# for key, value in ntas.items():
#     poly=Polygon(value)
#     print (poly)
#     break

# print()
# print(poly.contains(Point(green.dataFrame['pickup_longitude'][0],green.dataFrame['pickup_latitude'][0])))
#green.dataFrame["nta"]= green.dataFrame.apply(lambda row: settingNta(row['pickup_latitude'],row['pickup_longitude']),axis=1)

# import tqdm                               
# import numpy as np
# import pandas as pd
# from concurrent.futures import ProcessPoolExecutor, as_completed
# from multiprocessing import freeze_support, cpu_count
# num_processes = cpu_count()

# from DS4A.worker import func

# if __name__ == '__main__':
   
#     df = pd.DataFrame({i: np.random.randint(1,10,size=100) for i in ['a', 'b', 'c']})
#     # Process the rows in chunks in parallel
#     print("Starting ...")
#     with ProcessPoolExecutor(1) as pool:
#         #df['result'] = list(pool.map(func, df['a'], df['b'], chunksize=10)) # Without a progressbar
#         df['result'] = list(tqdm.tqdm(pool.map(func, df['a'], df['b'], chunksize=10), total=df.shape[0])) # With a progressbar

#     print(df)

#Multiprocessing in windows needs to run in __main__ module. Also, it wont work in interactive interpreter.

# print()
# print("Starting nta process ...")

# green.dataFrame["nta"]= p_map(settingNta, green.dataFrame["pickup_latitude"], green.dataFrame["pickup_longitude"])
# green.dataFrame.to_csv('myFile.csv',encoding='utf-8',index=False)
# green.dataFrame.head()   

# with concurrent.futures.ProcessPoolExecutor(max_workers=3) as pool:
#     green.dataFrame["nta"]= list(tqdm(pool.map(settingNta, green.dataFrame["pickup_latitude"], green.dataFrame["pickup_longitude"], chunksize=10),green.dataFrame.shape[0]))
#     green.dataFrame.to_csv('myFile.csv',encoding='utf-8',index=False)
#     green.dataFrame.head() 